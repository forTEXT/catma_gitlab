{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter Annotator Agreement (IAA) with gitma\n",
    "This demo uses the demo CATMA project.\n",
    "If you want to use it for your own annotations you first have to clone your CATMA project locally.\n",
    "For further information about cloning your CATMA project see [this notebook](https://github.com/forTEXT/gitma/blob/main/demo_notebooks/load_project_from_gitlab.ipynb).\n",
    "\n",
    "This package provides two methods to compute the agreement of two or more annotators.\n",
    "Both methods compare annotation collections.\n",
    "For that reason, it is recommended to use one annotation collection per annotator and document.\n",
    "Additionally, it is recommended to name every annotation collection by a combination of the <span style=\"color:pink\">document's title</span>, the <span style=\"color:red\">annotation task</span> and the <span style=\"color:green\">annotator</span>.\n",
    "\n",
    "**Example:**  <span style=\"color:pink\">robinson_crusoe</span>-<span style=\"color:red\">narrative_space</span>-<span style=\"color:green\">mareike</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Dependencies](#1-bullet)\n",
    "* [`get_iaa()`](#2-bullet)\n",
	"  * [Basic example](#2.1)\n",
	"  * [Filter by tags](#2.2)\n",
	"  * [Compare annotation properties](#2.3)\n",
    "* [`gamma_agreement()`](#3-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies <a class=\"anchor\" id=\"1-bullet\"></a>\n",
    "\n",
    "### nltk\n",
    "\n",
    "If you are only interested in IAA metrics such as *Scott's pi*, *Cohen's kappa* and *Krippendorf's alpha*\n",
    "the [Natural Language Toolkit](https://www.nltk.org/) is sufficient (already installed).\n",
    "\n",
    "### pygamma-agreement\n",
    "\n",
    "The gamma agreement takes unitizing as part of annotation tasks into account\n",
    "(see [Mathet et al. 2015](https://aclanthology.org/J15-3003.pdf)).\n",
    "For many annotation projects done within CATMA that might be crucial.\n",
    "If you want to compute the gamma agreement using this package, the installation of [pygamma-agreement](https://github.com/bootphon/pygamma-agreement) is required:\n",
    "\n",
    "    pip install pygamma-agreement\n",
    "\n",
    "Please take note of the **further installation instructions** on the [pygamma-agreement GitHub page](https://github.com/bootphon/pygamma-agreement#installation) and the [*'how to cite'*](https://github.com/bootphon/pygamma-agreement#citing-pygamma)!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the CatmaProject class\n",
    "from gitma import CatmaProject\n",
    "\n",
    "# load your project\n",
    "my_project = CatmaProject(\n",
    "    project_name='test_corpus',\n",
    "    project_directory='../test/demo_project/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `get_iaa()` <a class=\"anchor\" id=\"2-bullet\"></a>\n",
    "\n",
    "The test project contains three annotation collections.\n",
    "In this demo we will compute the agreement of the collections 'ac_1' and 'ac_2'.\n",
    "\n",
    "For every annotation in annotation collection 1 (`ac1_name`) the `get_iaa` method searches for the best matching annotation\n",
    "in annotation collection 2 (`ac2_name`) with respect to its annotation text span.\n",
    "The following examples show how matching annotations in two annotation collections are identified:\n",
    "\n",
    "<img src=\"demo_img/best_match_example_iaa.png\">\n",
    "\n",
    "In contrast to the `gamma_agreement` method (see below), the `get_iaa` method only considers the best matching annotations\n",
    "from both annotation collections when computing the IAA value.\n",
    "\n",
    "### Basic example <a class=\"anchor\" id=\"2.1\"></a>\n",
    "\n",
    "First, we will take look at both annotation collections by comparing the annotation spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the annotation collections by start point\n",
    "my_project.compare_annotation_collections(\n",
    "    annotation_collections=['ac_1', 'ac_2']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the line plot shows, every annotation in annotation collection 'ac_1' has a matching annotation in annotation collection 'ac_2'.\n",
    "\n",
    "Now, let's compute the IAA for all matching annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project.get_iaa(\n",
    "    ac1_name='ac_1',\n",
    "    ac2_name='ac_2'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_iaa` method not only returns 3 different agreement scores,\n",
    "but also reports the number of annotation pairs considered when computing the IAA scores\n",
    "and the average overlap of the annotation pairs.\n",
    "Additionally, the method returns a confusion matrix to give an insight into the relation between the tags.\n",
    "As you can see in the matrix, in 3 cases an annotation with the tag 'stative_event' in annotation collection 1\n",
    "has a best match in annotation collection 2 with the same tag.\n",
    "These are the first 3 annotations in annotation collection 1, as the line plot above shows.\n",
    "\n",
    "### Filter by tags <a class=\"anchor\" id=\"2.2\"></a>\n",
    "\n",
    "There may occur cases in which you don't want to include all annotations in the computing of\n",
    "the IAA scores.\n",
    "In those cases just use the `tag_filter` parameter, which expects a list of tag names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project.get_iaa(\n",
    "    ac1_name='ac_1',\n",
    "    ac2_name='ac_2',\n",
    "    tag_filter=['process']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the confusion matrix shows, only the annotations from annotation collection 1\n",
    "with the tag 'process' have been taken into account.\n",
    "From annotation collection 2 there is still one annotation considered with the tag 'stative_event'.\n",
    "But we can filter both annotation collections, too: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project.get_iaa(\n",
    "    ac1_name='ac_1',\n",
    "    ac2_name='ac_2',\n",
    "    tag_filter=['process'],\n",
    "    filter_both_ac=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we only use two tags in the demo project this leads to the same IAA results.\n",
    "\n",
    "### Compare annotation properties <a class=\"anchor\" id=\"2.3\"></a>\n",
    "\n",
    "The tag is only one level of CATMA annotations.\n",
    "If you want to compare annotations by their properties this is possible too.\n",
    "In the demo project the annotations have the property 'mental' to evaluate if a mental\n",
    "event is referenced in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project.compare_annotation_collections(\n",
    "    annotation_collections=['ac_1', 'ac_2'],\n",
    "    color_col='prop:mental'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the agreement of annotation properties you just have to use the `level` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project.get_iaa(\n",
    "    ac1_name='ac_1',\n",
    "    ac2_name='ac_2',\n",
    "    level='prop:mental'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows that in some cases the `get_iaa` method ignores disagreeing annotations,\n",
    "because they are not the best matching annotations.\n",
    "In the last annotation span of annotation collection 1 we can find one discontinuous and one embedded annotation.\n",
    "But only the discontinuous annotation is considered when computing the IAA because it is the better match to\n",
    "the last annotation in annotation collection 1.\n",
    "\n",
    "Again, if unitizing plays an important role in your annotation task we recommend the `gamma_agreement` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `gamma_agreement()` <a class=\"anchor\" id=\"3-bullet\"></a>\n",
    "\n",
    "To compute the gamma agreement, in addition to the annotation collections, 5 further parameters\n",
    "have to be defined.\n",
    "The `alpha`, `beta` and `delta_empty` parameters are necessary to compute the\n",
    "[`CombinedCategoricalDissimilarity`](https://github.com/bootphon/pygamma-agreement/blob/master/pygamma_agreement/dissimilarity.py#L467).\n",
    "The `n_samples` and the `precision_level` values are used in the \n",
    "[`compute_gamma()` method](https://github.com/bootphon/pygamma-agreement/blob/master/pygamma_agreement/continuum.py#L805).\n",
    "See the documentation for pygamma-agreement and\n",
    "[Mathet et al. 2015](https://aclanthology.org/J15-3003.pdf)\n",
    "for further information about these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma agreement with default settings\n",
    "my_project.gamma_agreement(\n",
    "    annotation_collections=['ac_1', 'ac_2'],\n",
    "    alpha=3,\n",
    "    beta=1,\n",
    "    delta_empty=0.01,\n",
    "    n_samples=30,\n",
    "    precision_level=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to work with a different dissimillarity algorithm\n",
    "consider using pygamma-agreement directly.\n",
    "For this purpose you can save all annotations in a project as a CSV file\n",
    "in the format pygamma-agreement takes as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygamma_df = my_project.pygamma_table(\n",
    "    annotation_collections=['ac_1', 'ac_2']\n",
    ")\n",
    "\n",
    "# save\n",
    "pygamma_df.to_csv('../test/pygamma_table.csv', index=False, header=False)\n",
    "\n",
    "# show example\n",
    "pygamma_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0aeb839bc1fa9071e2c89c506d6a5f005efc3f16a8f217a2b2b732963ddcf6b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.gitma_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
